# ML dataScience Basics

## Important Architectures/Algorithms

### Basics
* Regularization : 
    * https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a
* Bayes Theorm :
    * https://en.wikipedia.org/wiki/Bayes%27_theorem

### Neural Networks 
* Optimal brain damage algorithm (CNN compression) : 
    * http://yann.lecun.com/exdb/publis/pdf/lecun-90b.pdf
* Cascade correlation (network) learning architecture : 
    * http://papers.nips.cc/paper/207-the-cascade-correlation-learning-architecture.pdf
* Avoiding local optima using simulated annealing : 
    * https://en.wikipedia.org/wiki/Simulated_annealing 
    * http://www.cs.cmu.edu/afs/cs.cmu.edu/project/learn-43/lib/photoz/.g/web/glossary/anneal.html
* Parameter Estimation (Maximum Likelihood Estimation): 
    * http://statweb.stanford.edu/~susan/courses/s200/lectures/lect11.pdf

### Decision Trees 
* Regression Trees - Model Trees : 
    * https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205
    * https://towardsdatascience.com/introduction-to-model-trees-6e396259379a
* Cross Validation (Very Important) : 
    * https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f
* Bagging and boosting :
    * https://towardsdatascience.com/decision-tree-ensembles-bagging-and-boosting-266a8ba60fd9
    *Boosting is a very powerful tool works really well with decision trees*
    * Random Forests - 
         * https://towardsdatascience.com/understanding-random-forest-58381e0602d2

### Evaluation/ Evaluation measures
* Bootstrapping :
    * https://towardsdatascience.com/an-introduction-to-the-bootstrap-method-58bcb51b4d60
* Explaination to Accuracy, Recall, Precision, F-Score, Specificity and sensitivity : 
    * https://towardsdatascience.com/accuracy-recall-precision-f-score-specificity-which-to-optimize-on-867d3f11124
* Supervised-Learning : Ranking :
    * https://medium.com/@nikhilbd/intuitive-explanation-of-learning-to-rank-and-ranknet-lambdarank-and-lambdamart-fe1e17fac418
    * https://towardsdatascience.com/learning-to-rank-with-python-scikit-learn-327a5cfd81f

### Graphical Models 
* Basics 
    * http://mlg.eng.cam.ac.uk/zoubin/talks/lect2gm.pdf
* Markov Blanket for directed and undirected graphs 
    * https://library.bayesia.com/display/FAQ/Markov+Blankets
* Hammersleyâ€“Clifford theorem
    * https://en.wikipedia.org/wiki/Hammersley%E2%80%93Clifford_theorem
* Representation of Undirected Graphical Model     
    * https://www.cs.cmu.edu/~epxing/Class/10708-17/notes-17/10708-scribe-lecture3.pdf
* Hidden Markov Model - useful in NLP context 
    * https://medium.com/@kangeugine/hidden-markov-model-7681c22f5b9
    * https://medium.com/greyatom/learning-pos-tagging-chunking-in-nlp-85f7f811a8cb
    * Chunking :
        * https://nlpforhackers.io/text-chunking/
